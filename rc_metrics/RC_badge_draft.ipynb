{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rc_util import * \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29374.97091293335"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a graph from the JSON-LD corpus\n",
    "net = RCNetwork()\n",
    "\n",
    "# parses, builds NetworkX graph, and creates default \"rank\" for each entity\n",
    "net.load_network(\"full.jsonld\") # net.load_network(\"../../rclc/corpus.jsonld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has: \n",
      "--619 datasets \n",
      "--3,816 publications \n",
      "--378 providers \n",
      "--8,249 authors\n"
     ]
    }
   ],
   "source": [
    "# profile corpus\n",
    "num_datasets = len(set(net.data.keys()))\n",
    "\n",
    "num_publications = len(set(net.publ.keys()))\n",
    "\n",
    "num_providers = len(set(net.prov.keys()))\n",
    "\n",
    "num_authors = len(set(net.auth.keys()))\n",
    "\n",
    "print(\"this corpus has: \\n--{:,.0f} datasets \\n--{:,.0f} publications \\n--{:,.0f} providers \\n--{:,.0f} authors\".format(\n",
    "num_datasets, num_publications, num_providers, num_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset RC-IDs for 4 target datasets: FoodAPS, ARMS, IRI InfoScan & Consumer Network\n",
    "data_list = ['dataset-955eb4bf66b73016354c', # ARMS\n",
    "             'dataset-fc71e81f1f2c4130d897', # FoodAPS\n",
    "            'dataset-ae01c2bf3451493f3620',  # IRI Consumer Network\n",
    "             'dataset-cb23c2370049f4960a3a'] # IRI InfoScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset-955eb4bf66b73016354c | Agricultural Resource Management Survey |  has 320 publications\n",
      "dataset-fc71e81f1f2c4130d897 | FoodAPS National Household Food Acquisition and Purchase Survey |  has 35 publications\n",
      "dataset-ae01c2bf3451493f3620 | IRI Consumer Network |  has 27 publications\n",
      "dataset-cb23c2370049f4960a3a | IRI Infoscan |  has 88 publications\n"
     ]
    }
   ],
   "source": [
    "# simple count of publications for each dataset:\n",
    "for rc_id in data_list:\n",
    "    # gather  info from 'recommender'; it sorts the publications based on Eigenvector calc of 'rank'\n",
    "    uuid, title, rank, url, provider, publ_list = net.reco_data(net.data[rc_id])\n",
    "    print('{} | {} |  has {} publications'.format(rc_id, title,len(publ_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. dataset name\n",
    "2. number of publications\n",
    "3. number of combined datasets\n",
    "4. top 5 datasets and their providers\n",
    "5. number of authors\n",
    "6. top 5 authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test steps for one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build on existing function to generate metrics\n",
    "uuid, title, rank, url, provider, publ_list = net.reco_data(net.data['dataset-ae01c2bf3451493f3620'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.data['dataset-ae01c2bf3451493f3620'].view['title'])\n",
    "print(len(publ_list))\n",
    "joined_datasets = {}\n",
    "joined_data_counts = {}\n",
    "authors_dict = {}\n",
    "authors_count = {}\n",
    "for pubid, pub, pubrank in publ_list:\n",
    "    d_list = net.publ[net.id_list[pubid]].view['datasets'].copy()\n",
    "    d_list.remove(uuid) # don't include current dataset\n",
    "    for d in d_list:\n",
    "        if d in joined_datasets.keys():\n",
    "            joined_data_counts[d] += 1\n",
    "        else:\n",
    "            joined_datasets[d] = net.data[d].view\n",
    "            joined_data_counts[d] = 1\n",
    "            joined_datasets[d]['ProvName'] = net.prov[joined_datasets[d]['provider']].view['title']\n",
    "    a_list = net.publ[net.id_list[pubid]].view['authors'].copy()\n",
    "    for a in a_list:\n",
    "        if a in authors_dict.keys():\n",
    "            authors_count[a] += 1\n",
    "        else:\n",
    "            authors_dict[a] = net.auth[a].view\n",
    "            authors_count[a] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_datasets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_datasets['dataset-17fbd0c3d561e8260ab3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get top 5 authors\n",
    "sorted(authors_count.items(), key=lambda t: t[1], reverse=-True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(joined_data_counts.items(), key=lambda t: t[1], reverse=-True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_id, data_count in sorted(joined_data_counts.items(), key=lambda t: t[1], reverse=-True)[:5]:\n",
    "    DataName = joined_datasets[data_id]['title']\n",
    "    DataProv = net.prov[joined_datasets[data_id]['provider']].view['title']\n",
    "    print('Dataset {} by {} joined {} times'.format(DataName,DataProv,data_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for auth_id, auth_count in sorted(authors_count.items(), key=lambda t: t[1], reverse=-True)[:5]:\n",
    "    AuthName = authors_dict[auth_id]['title']\n",
    "    AuthORCID = authors_dict[auth_id]['orcid']\n",
    "    print('{} | {} | used dataset {} times'.format(AuthName, AuthORCID, auth_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work through specified list of datasets\n",
    "metrics to generate for each:\n",
    "- number of publications\n",
    "- number of combined datasets\n",
    "- top 5 datasets and their providers\n",
    "- number of authors\n",
    "- top 5 authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting measures for Agricultural Resource Management Survey\n",
      "-- used in 320 publications\n",
      "-- 72 datasets were combined with this dataset. The top 5 are:\n",
      "---- Census of Agriculture by US Department of Agriculture joined 25 times\n",
      "---- Soil Survey Geographic Database by US Department of Agriculture joined 5 times\n",
      "---- Cropland Data Layer by US Department of Agriculture joined 5 times\n",
      "---- Survey of Consumer Finance by Federal Reserve System joined 5 times\n",
      "---- USDA Fertilizer Use and Price by US Department of Agriculture joined 4 times\n",
      "-- 545 authors used this dataset. The top 5 are:\n",
      "---- Mishra, Ashok K. | ORCID = https://orcid.org/0000-0002-0988-1428 | used dataset 44 times\n",
      "---- Key, Nigel D. | ORCID = https://orcid.org/0000-0002-0290-8608 | used dataset 15 times\n",
      "---- Gillespie, Jeffrey M. | ORCID = unknown | used dataset 15 times\n",
      "---- El-Osta, Hisham Said | ORCID = unknown | used dataset 15 times\n",
      "---- Nehring, Richard F. | ORCID = unknown | used dataset 14 times\n",
      "\n",
      "collecting measures for FoodAPS National Household Food Acquisition and Purchase Survey\n",
      "-- used in 35 publications\n",
      "-- 3 datasets were combined with this dataset. The top 5 are:\n",
      "---- The Healthy Eating Index by US Department of Agriculture joined 2 times\n",
      "---- Supplemental Nutrition Assistance Program by US Department of Agriculture joined 1 times\n",
      "---- Current Population Survey Food Security Supplement by US Census Bureau joined 1 times\n",
      "-- 73 authors used this dataset. The top 5 are:\n",
      "---- Ver Ploeg, Michele | ORCID = unknown | used dataset 7 times\n",
      "---- Mancino, Lisa | ORCID = unknown | used dataset 4 times\n",
      "---- Wilde, Parke E. | ORCID = https://orcid.org/0000-0002-9596-9230 | used dataset 4 times\n",
      "---- Gregory, Christian A. | ORCID = unknown | used dataset 4 times\n",
      "---- Dong, Diansheng | ORCID = https://orcid.org/0000-0003-0783-3171 | used dataset 3 times\n",
      "\n",
      "collecting measures for IRI Consumer Network\n",
      "-- used in 27 publications\n",
      "-- 4 datasets were combined with this dataset. The top 5 are:\n",
      "---- IRI Infoscan by IRI joined 10 times\n",
      "---- National Health and Nutrition Examination Survey by Centers for Disease Control and Prevention joined 2 times\n",
      "---- Food Security Survey Module by US Department of Agriculture joined 1 times\n",
      "---- Food Composition Databases by US Department of Agriculture joined 1 times\n",
      "-- 56 authors used this dataset. The top 5 are:\n",
      "---- Volpe, Richard James | ORCID = unknown | used dataset 4 times\n",
      "---- Zhen, Cheng | ORCID = https://orcid.org/0000-0002-6087-7387 | used dataset 3 times\n",
      "---- Muth, Mary K. | ORCID = https://orcid.org/0000-0001-7879-0469 | used dataset 3 times\n",
      "---- Kuhns, Annemarie | ORCID = unknown | used dataset 3 times\n",
      "---- Rahkovsky, Ilya M. | ORCID = unknown | used dataset 2 times\n",
      "\n",
      "collecting measures for IRI Infoscan\n",
      "-- used in 88 publications\n",
      "-- 5 datasets were combined with this dataset. The top 5 are:\n",
      "---- IRI Consumer Network by IRI joined 10 times\n",
      "---- National Health and Nutrition Examination Survey by Centers for Disease Control and Prevention joined 2 times\n",
      "---- Food Security Survey Module by US Department of Agriculture joined 1 times\n",
      "---- Food Composition Databases by US Department of Agriculture joined 1 times\n",
      "---- Massachusetts Department of Revenue Longitudinal Employer Filings by Massachusetts Department of Revenue joined 1 times\n",
      "-- 185 authors used this dataset. The top 5 are:\n",
      "---- Lopez, Rigoberto A. | ORCID = unknown | used dataset 5 times\n",
      "---- Rahkovsky, Ilya M. | ORCID = unknown | used dataset 4 times\n",
      "---- Kuchler, Fred | ORCID = https://orcid.org/0000-0001-5874-1619 | used dataset 4 times\n",
      "---- Rojas, Christian | ORCID = unknown | used dataset 4 times\n",
      "---- Bonannoxs, Alessandro | ORCID = unknown | used dataset 3 times\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_metrics = {} # object to hold resulting metrics calculated below\n",
    "\n",
    "for this_data in data_list:\n",
    "    # build on existing function to generate metrics\n",
    "    uuid, title, rank, url, provider, publ_list = net.reco_data(net.data[this_data])\n",
    "    print('collecting measures for {}'.format(title))\n",
    "    num_pubs = len(publ_list)\n",
    "    print('-- used in {} publications'.format(num_pubs))\n",
    "    joined_datasets = {}\n",
    "    joined_data_counts = {}\n",
    "    authors_dict = {}\n",
    "    authors_count = {}\n",
    "    for pubid, pub, pubrank in publ_list:\n",
    "        # get datasets used in publication\n",
    "        d_list = net.publ[net.id_list[pubid]].view['datasets'].copy()\n",
    "        d_list.remove(uuid) # don't include current dataset\n",
    "        for d in d_list:\n",
    "            if d in joined_datasets.keys():\n",
    "                joined_data_counts[d] += 1\n",
    "            else:\n",
    "                joined_datasets[d] = net.data[d].view\n",
    "                joined_data_counts[d] = 1\n",
    "                joined_datasets[d]['ProvName'] = net.prov[joined_datasets[d]['provider']].view['title']\n",
    "        a_list = net.publ[net.id_list[pubid]].view['authors'].copy()\n",
    "        for a in a_list:\n",
    "            if a in authors_dict.keys():\n",
    "                authors_count[a] += 1\n",
    "            else:\n",
    "                authors_dict[a] = net.auth[a].view\n",
    "                authors_count[a] = 1\n",
    "    # add results to dataset_metrics dict:\n",
    "    dataset_metrics[uuid] = {'combinedDatasets': joined_datasets, 'combinedDataCounts': joined_data_counts,\n",
    "                            'PubAuthors': authors_dict, 'AuthorCounts': authors_count,\n",
    "                            'TotalPublications': num_pubs, 'PubIDs': publ_list}\n",
    "    \n",
    "    ## print selected gathered info:\n",
    "    # total datasets\n",
    "    print('-- {} datasets were combined with this dataset. The top 5 are:'.format(len(joined_datasets.keys())))\n",
    "    # top 5 datasets\n",
    "    for data_id, data_count in sorted(joined_data_counts.items(), key=lambda t: t[1], reverse=-True)[:5]:\n",
    "        DataName = joined_datasets[data_id]['title']\n",
    "        DataProv = joined_datasets[data_id]['ProvName']\n",
    "        print('---- {} by {} joined {} times'.format(DataName,DataProv,data_count))\n",
    "    # total authors:\n",
    "    print('-- {} authors used this dataset. The top 5 are:'.format(len(authors_dict.keys())))\n",
    "    # top 5 authors:\n",
    "    for auth_id, auth_count in sorted(authors_count.items(), key=lambda t: t[1], reverse=-True)[:5]:\n",
    "        AuthName = authors_dict[auth_id]['title']\n",
    "        AuthORCID = authors_dict[auth_id]['orcid']\n",
    "        if AuthORCID=='':\n",
    "            AuthORCID = 'unknown'\n",
    "        print('---- {} | ORCID = {} | used dataset {} times'.format(AuthName, AuthORCID, auth_count))\n",
    "    print('') # add line between each datast summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dataset-955eb4bf66b73016354c', 'dataset-fc71e81f1f2c4130d897', 'dataset-ae01c2bf3451493f3620', 'dataset-cb23c2370049f4960a3a'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can access all results if need to report out differently, eg number of datasets:\n",
    "len(dataset_metrics['dataset-955eb4bf66b73016354c']['combinedDatasets'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RCServer",
   "language": "python",
   "name": "rcserver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
