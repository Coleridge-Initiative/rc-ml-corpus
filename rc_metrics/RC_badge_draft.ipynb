{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rc_util import * \n",
    "from richcontext import scholapi as rc_scholapi # pip install richcontext.scholapi\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from rcgraph.richcontext import graph as rc_graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25123.997926712036"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a graph from the JSON-LD corpus\n",
    "net = RCNetwork()\n",
    "\n",
    "# parses, builds NetworkX graph, and creates default \"rank\" for each entity\n",
    "net.load_network(\"full.jsonld\") # net.load_network(\"../../rclc/corpus.jsonld\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this corpus has: \n",
      "--619 datasets \n",
      "--3,816 publications \n",
      "--378 providers \n",
      "--8,249 authors\n"
     ]
    }
   ],
   "source": [
    "# profile corpus\n",
    "num_datasets = len(set(net.data.keys()))\n",
    "\n",
    "num_publications = len(set(net.publ.keys()))\n",
    "\n",
    "num_providers = len(set(net.prov.keys()))\n",
    "\n",
    "num_authors = len(set(net.auth.keys()))\n",
    "\n",
    "print(\"this corpus has: \\n--{:,.0f} datasets \\n--{:,.0f} publications \\n--{:,.0f} providers \\n--{:,.0f} authors\".format(\n",
    "num_datasets, num_publications, num_providers, num_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset RC-IDs for 4 target datasets: FoodAPS, ARMS, IRI InfoScan & Consumer Network\n",
    "data_list = ['dataset-955eb4bf66b73016354c', # ARMS\n",
    "             'dataset-fc71e81f1f2c4130d897', # FoodAPS\n",
    "            'dataset-ae01c2bf3451493f3620',  # IRI Consumer Network\n",
    "             'dataset-cb23c2370049f4960a3a'] # IRI InfoScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset-955eb4bf66b73016354c | Agricultural Resource Management Survey |  has 320 publications\n",
      "dataset-fc71e81f1f2c4130d897 | FoodAPS National Household Food Acquisition and Purchase Survey |  has 35 publications\n",
      "dataset-ae01c2bf3451493f3620 | IRI Consumer Network |  has 27 publications\n",
      "dataset-cb23c2370049f4960a3a | IRI Infoscan |  has 88 publications\n"
     ]
    }
   ],
   "source": [
    "# simple count of publications for each dataset:\n",
    "for rc_id in data_list:\n",
    "    # gather  info from 'recommender'; it sorts the publications based on Eigenvector calc of 'rank'\n",
    "    uuid, title, rank, url, provider, publ_list = net.reco_data(net.data[rc_id])\n",
    "    print('{} | {} |  has {} publications'.format(rc_id, title,len(publ_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. dataset name\n",
    "2. number of publications\n",
    "3. number of combined datasets\n",
    "4. top 5 datasets and their providers\n",
    "5. number of authors\n",
    "6. top 5 authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test steps for one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build on existing function to generate metrics\n",
    "uuid, title, rank, url, provider, publ_list = net.reco_data(net.data['dataset-ae01c2bf3451493f3620'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_institution(orcid,institutions_dict, institutions_count):\n",
    "    hit = False\n",
    "\n",
    "    # get orcid institution\n",
    "    if len(net.auth[a].view[\"orcid\"]) > 19:\n",
    "        orcid = net.auth[a].view[\"orcid\"][-19:]\n",
    "\n",
    "    result = schol.orcid.affiliations(orcid)\n",
    "    result2 = schol.orcid.funding(orcid)\n",
    "    if result.meta:\n",
    "        hit = True\n",
    "        if isinstance(result.meta, list):\n",
    "            institution = result.meta[0]['employment:organization']\n",
    "        else:\n",
    "            institution = result.meta['employment:organization']\n",
    "        #print(orcid, institution['common:name'])\n",
    "\n",
    "        if institution['common:name'] in institutions_dict.keys():\n",
    "            institutions_count[institution['common:name']] += 1\n",
    "        else:\n",
    "            institutions_dict[institution['common:name']] = institution  # TODO potentially show countries?\n",
    "            institutions_count[institution['common:name']] = 1\n",
    "    if result2.meta:\n",
    "        #print(\"TODO, look at schol.orcid.funding(orcid) for\", orcid)\n",
    "        funding.append(result2.meta)\n",
    "    return hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all KG known authors\n",
    "graph = rc_graph.RCGraph()\n",
    "graph.authors.load_entities(\"../rcgraph/authors.json\") \n",
    "\n",
    "# load all Dimensions raw metadata from publications\n",
    "dimension_pubs = {}\n",
    "for partition, pub_iter in graph.iter_publications(\"../rcgraph/bucket_stage\"):\n",
    "    for pub in pub_iter:\n",
    "        if \"Dimensions\" in pub:\n",
    "            if \"authors\" in pub[\"Dimensions\"]:\n",
    "                dimension_pubs[pub[\"title\"]] = pub[\"Dimensions\"][\"authors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_institution_from_dimensions(pub,author_uuid):\n",
    "    if author_uuid in graph.authors.known.uuid_map:\n",
    "        if \"dimensions\" in graph.authors.known.uuid_map[author_uuid]:\n",
    "            researcher_id = graph.authors.known.uuid_map[author_uuid][\"dimensions\"]\n",
    "            if pub in dimension_pubs:\n",
    "                for dimensions_meta in dimension_pubs[pub]:\n",
    "                    if dimensions_meta[\"researcher_id\"] == researcher_id:\n",
    "                        try:\n",
    "                            institution_name = dimensions_meta[\"affiliations\"][0][\"name\"]\n",
    "\n",
    "                            if institution_name in institutions_dict.keys():\n",
    "                                institutions_count[institution_name] += 1\n",
    "                            else:\n",
    "                                institutions_dict[institution_name] = dimensions_meta[\"affiliations\"][0]  # TODO potentially show countries?\n",
    "                                institutions_count[institution_name] = 1\n",
    "                        except:\n",
    "                            pass\n",
    "                        return True\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRI Consumer Network\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "funding = []\n",
    "\n",
    "\n",
    "print(net.data['dataset-ae01c2bf3451493f3620'].view['title'])\n",
    "print(len(publ_list))\n",
    "joined_datasets = {}\n",
    "joined_data_counts = {}\n",
    "authors_dict = {}\n",
    "authors_count = {}\n",
    "institutions_dict = {}\n",
    "institutions_count = {}\n",
    "authorsWithInstitution_count = 0\n",
    "schol = rc_scholapi.ScholInfraAPI(config_file=\"rc.cfg\", logger=None)\n",
    "\n",
    "for pubid, pub, pubrank in publ_list:\n",
    "    d_list = net.publ[net.id_list[pubid]].view['datasets'].copy()\n",
    "    d_list.remove(uuid) # don't include current dataset\n",
    "    for d in d_list:\n",
    "        if d in joined_datasets.keys():\n",
    "            joined_data_counts[d] += 1\n",
    "        else:\n",
    "            joined_datasets[d] = net.data[d].view\n",
    "            joined_data_counts[d] = 1\n",
    "            joined_datasets[d]['ProvName'] = net.prov[joined_datasets[d]['provider']].view['title']\n",
    "    a_list = net.publ[net.id_list[pubid]].view['authors'].copy()\n",
    "    for a in a_list:\n",
    "        if a in authors_dict.keys():\n",
    "            authors_count[a] += 1\n",
    "        else:\n",
    "            authors_dict[a] = net.auth[a].view\n",
    "            authors_count[a] = 1\n",
    "            \n",
    "            # for each dataset, count the institution only once per author. If the author wrote several publications, it will account for only one institution count.\n",
    "            if net.auth[a].view[\"orcid\"]:\n",
    "                hit = extract_institution(net.auth[a].view[\"orcid\"], institutions_dict, institutions_count)\n",
    "                if hit:\n",
    "                    authorsWithInstitution_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined_datasets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_datasets['dataset-17fbd0c3d561e8260ab3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get top 5 authors\n",
    "sorted(authors_count.items(), key=lambda t: t[1], reverse=-True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(joined_data_counts.items(), key=lambda t: t[1], reverse=-True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_id, data_count in sorted(joined_data_counts.items(), key=lambda t: t[1], reverse=-True)[:5]:\n",
    "    DataName = joined_datasets[data_id]['title']\n",
    "    DataProv = net.prov[joined_datasets[data_id]['provider']].view['title']\n",
    "    print('Dataset {} by {} joined {} times'.format(DataName,DataProv,data_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for auth_id, auth_count in sorted(authors_count.items(), key=lambda t: t[1], reverse=-True)[:5]:\n",
    "    AuthName = authors_dict[auth_id]['title']\n",
    "    AuthORCID = authors_dict[auth_id]['orcid']\n",
    "    print('{} | {} | used dataset {} times'.format(AuthName, AuthORCID, auth_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### work through specified list of datasets\n",
    "metrics to generate for each:\n",
    "- number of publications\n",
    "- number of combined datasets\n",
    "- top 5 datasets and their providers\n",
    "- number of authors\n",
    "- top 5 authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting measures for Agricultural Resource Management Survey\n",
      "-- used in 320 publications\n",
      "-- 72 datasets were combined with this dataset. The top 5 are:\n",
      "---- Census of Agriculture by US Department of Agriculture joined 25 times\n",
      "---- Soil Survey Geographic Database by US Department of Agriculture joined 5 times\n",
      "---- Cropland Data Layer by US Department of Agriculture joined 5 times\n",
      "---- Survey of Consumer Finance by Federal Reserve System joined 5 times\n",
      "---- USDA Fertilizer Use and Price by US Department of Agriculture joined 4 times\n",
      "-- 545 authors used this dataset. The top 5 are:\n",
      "---- Mishra, Ashok K. | ORCID = https://orcid.org/0000-0002-0988-1428 | used dataset 44 times\n",
      "---- Key, Nigel D. | ORCID = https://orcid.org/0000-0002-0290-8608 | used dataset 15 times\n",
      "---- Gillespie, Jeffrey M. | ORCID = unknown | used dataset 15 times\n",
      "---- El-Osta, Hisham Said | ORCID = unknown | used dataset 15 times\n",
      "---- Nehring, Richard F. | ORCID = unknown | used dataset 14 times\n",
      "-- 118 institutions used this dataset. The top 5 are:\n",
      "---- U.S. Department of Agriculture (USDA) - Economic Research Service (ERS) | used dataset 8 times\n",
      "---- Economic Research Service | used dataset 7 times\n",
      "---- Michigan State University | used dataset 7 times\n",
      "---- University of Minnesota | used dataset 6 times\n",
      "---- University of Nebraskaâ€“Lincoln | used dataset 6 times\n",
      "------ Note: of the 545 authors, we were able to find institutions for 196 of them\n",
      "\n",
      "collecting measures for FoodAPS National Household Food Acquisition and Purchase Survey\n",
      "-- used in 35 publications\n",
      "-- 3 datasets were combined with this dataset. The top 5 are:\n",
      "---- The Healthy Eating Index by US Department of Agriculture joined 2 times\n",
      "---- Supplemental Nutrition Assistance Program by US Department of Agriculture joined 1 times\n",
      "---- Current Population Survey Food Security Supplement by US Census Bureau joined 1 times\n",
      "-- 73 authors used this dataset. The top 5 are:\n",
      "---- Ver Ploeg, Michele | ORCID = unknown | used dataset 7 times\n",
      "---- Mancino, Lisa | ORCID = unknown | used dataset 4 times\n",
      "---- Wilde, Parke E. | ORCID = https://orcid.org/0000-0002-9596-9230 | used dataset 4 times\n",
      "---- Gregory, Christian A. | ORCID = unknown | used dataset 4 times\n",
      "---- Dong, Diansheng | ORCID = https://orcid.org/0000-0003-0783-3171 | used dataset 3 times\n",
      "-- 18 institutions used this dataset. The top 5 are:\n",
      "---- Economic Research Service | used dataset 2 times\n",
      "---- CSIRO | used dataset 1 times\n",
      "---- Tufts University | used dataset 1 times\n",
      "---- University of Connecticut | used dataset 1 times\n",
      "---- University of Missouri | used dataset 1 times\n",
      "------ Note: of the 73 authors, we were able to find institutions for 26 of them\n",
      "\n",
      "collecting measures for IRI Consumer Network\n",
      "-- used in 27 publications\n",
      "-- 4 datasets were combined with this dataset. The top 5 are:\n",
      "---- IRI Infoscan by IRI joined 10 times\n",
      "---- National Health and Nutrition Examination Survey by Centers for Disease Control and Prevention joined 2 times\n",
      "---- Food Security Survey Module by US Department of Agriculture joined 1 times\n",
      "---- Food Composition Databases by US Department of Agriculture joined 1 times\n",
      "-- 56 authors used this dataset. The top 5 are:\n",
      "---- Volpe, Richard James | ORCID = unknown | used dataset 4 times\n",
      "---- Zhen, Cheng | ORCID = https://orcid.org/0000-0002-6087-7387 | used dataset 3 times\n",
      "---- Muth, Mary K. | ORCID = https://orcid.org/0000-0001-7879-0469 | used dataset 3 times\n",
      "---- Kuhns, Annemarie | ORCID = unknown | used dataset 3 times\n",
      "---- Rahkovsky, Ilya M. | ORCID = unknown | used dataset 2 times\n",
      "-- 17 institutions used this dataset. The top 5 are:\n",
      "---- University of Georgia | used dataset 2 times\n",
      "---- Northwestern University | used dataset 2 times\n",
      "---- CSIRO | used dataset 1 times\n",
      "---- Seoul National University Seoul Metropolitan Government Boramae Medical Center | used dataset 1 times\n",
      "---- RTI International | used dataset 1 times\n",
      "------ Note: of the 56 authors, we were able to find institutions for 19 of them\n",
      "\n",
      "collecting measures for IRI Infoscan\n",
      "-- used in 88 publications\n",
      "-- 5 datasets were combined with this dataset. The top 5 are:\n",
      "---- IRI Consumer Network by IRI joined 10 times\n",
      "---- National Health and Nutrition Examination Survey by Centers for Disease Control and Prevention joined 2 times\n",
      "---- Food Security Survey Module by US Department of Agriculture joined 1 times\n",
      "---- Food Composition Databases by US Department of Agriculture joined 1 times\n",
      "---- Massachusetts Department of Revenue Longitudinal Employer Filings by Massachusetts Department of Revenue joined 1 times\n",
      "-- 185 authors used this dataset. The top 5 are:\n",
      "---- Lopez, Rigoberto A. | ORCID = unknown | used dataset 5 times\n",
      "---- Rahkovsky, Ilya M. | ORCID = unknown | used dataset 4 times\n",
      "---- Kuchler, Fred | ORCID = https://orcid.org/0000-0001-5874-1619 | used dataset 4 times\n",
      "---- Rojas, Christian | ORCID = unknown | used dataset 4 times\n",
      "---- Bonannoxs, Alessandro | ORCID = unknown | used dataset 3 times\n",
      "-- 54 institutions used this dataset. The top 5 are:\n",
      "---- RTI International | used dataset 5 times\n",
      "---- University of Connecticut | used dataset 5 times\n",
      "---- United States Food and Drug Administration | used dataset 4 times\n",
      "---- Economic Research Service | used dataset 3 times\n",
      "---- University of North Carolina at Chapel Hill | used dataset 3 times\n",
      "------ Note: of the 185 authors, we were able to find institutions for 82 of them\n",
      "\n",
      "TODO: review funding found for  8 authors\n"
     ]
    }
   ],
   "source": [
    "funding = []\n",
    "schol = rc_scholapi.ScholInfraAPI(config_file=\"rc.cfg\", logger=None) # to access ORCID\n",
    "\n",
    "dataset_metrics = {} # object to hold resulting metrics calculated below\n",
    "\n",
    "for this_data in data_list:\n",
    "    # build on existing function to generate metrics\n",
    "    uuid, title, rank, url, provider, publ_list = net.reco_data(net.data[this_data])\n",
    "    print('collecting measures for {}'.format(title))\n",
    "    num_pubs = len(publ_list)\n",
    "    print('-- used in {} publications'.format(num_pubs))\n",
    "    joined_datasets = {}\n",
    "    joined_data_counts = {}\n",
    "    authors_dict = {}\n",
    "    authors_count = {}\n",
    "    institutions_dict = {}\n",
    "    institutions_count = {}\n",
    "    authorsWithInstitution_count = 0\n",
    "\n",
    "    for pubid, pub, pubrank in publ_list:\n",
    "        # get datasets used in publication\n",
    "        d_list = net.publ[net.id_list[pubid]].view['datasets'].copy()\n",
    "        d_list.remove(uuid) # don't include current dataset\n",
    "        for d in d_list:\n",
    "            if d in joined_datasets.keys():\n",
    "                joined_data_counts[d] += 1\n",
    "            else:\n",
    "                joined_datasets[d] = net.data[d].view\n",
    "                joined_data_counts[d] = 1\n",
    "                joined_datasets[d]['ProvName'] = net.prov[joined_datasets[d]['provider']].view['title']\n",
    "        a_list = net.publ[net.id_list[pubid]].view['authors'].copy()\n",
    "        for a in a_list:\n",
    "            if a in authors_dict.keys():\n",
    "                authors_count[a] += 1\n",
    "            else:\n",
    "                authors_dict[a] = net.auth[a].view\n",
    "                authors_count[a] = 1\n",
    "                \n",
    "                # extract institution first trying with author's ORCID (new pull) and then with Dimensions (existing metadata in RCGraph)\n",
    "                hit = False\n",
    "                if net.auth[a].view[\"orcid\"]:\n",
    "                    hit = extract_institution(net.auth[a].view[\"orcid\"], institutions_dict, institutions_count)\n",
    "                else:\n",
    "                    hit = extract_institution_from_dimensions(pub,a)\n",
    "                \n",
    "                if hit:\n",
    "                    authorsWithInstitution_count += 1\n",
    "\n",
    "    # add results to dataset_metrics dict:\n",
    "    dataset_metrics[uuid] = {'combinedDatasets': joined_datasets, 'combinedDataCounts': joined_data_counts,\n",
    "                            'PubAuthors': authors_dict, 'AuthorCounts': authors_count,\n",
    "                            'TotalPublications': num_pubs, 'PubIDs': publ_list,\n",
    "                             'AuthorInstitutions':institutions_dict, 'InstitutionCounts':institutions_count,\n",
    "                             'AuthorsWithInstitutionCounts':authorsWithInstitution_count}\n",
    "    \n",
    "    ## print selected gathered info:\n",
    "    # total datasets\n",
    "    print('-- {} datasets were combined with this dataset. The top 5 are:'.format(len(joined_datasets.keys())))\n",
    "    # top 5 datasets\n",
    "    for data_id, data_count in sorted(joined_data_counts.items(), key=lambda t: t[1], reverse=-True)[:5]:\n",
    "        DataName = joined_datasets[data_id]['title']\n",
    "        DataProv = joined_datasets[data_id]['ProvName']\n",
    "        print('---- {} by {} joined {} times'.format(DataName,DataProv,data_count))\n",
    "    # total authors:\n",
    "    print('-- {} authors used this dataset. The top 5 are:'.format(len(authors_dict.keys())))\n",
    "    # top 5 authors:\n",
    "    for auth_id, auth_count in sorted(authors_count.items(), key=lambda t: t[1], reverse=-True)[:5]:\n",
    "        AuthName = authors_dict[auth_id]['title']\n",
    "        AuthORCID = authors_dict[auth_id]['orcid']\n",
    "        if AuthORCID=='':\n",
    "            AuthORCID = 'unknown'\n",
    "        print('---- {} | ORCID = {} | used dataset {} times'.format(AuthName, AuthORCID, auth_count))\n",
    "    # total institutions:\n",
    "    print('-- {} institutions used this dataset. The top 5 are:'.format(len(institutions_dict.keys())))\n",
    "    # top 5 institutions:\n",
    "    for institution_name , institution_count in sorted(institutions_count.items(), key=lambda t: t[1], reverse=-True)[:5]:\n",
    "        InstitutionName = institution_name\n",
    "\n",
    "        print('---- {} | used dataset {} times'.format(InstitutionName, institution_count))\n",
    "\n",
    "    print('------ Note: of the {} authors, we were able to find institutions for {} of them'.format(\n",
    "        len(authors_dict.keys()), authorsWithInstitution_count))\n",
    "    print('') # add line between each datast summary\n",
    "\n",
    "\n",
    "print(\"TODO: review funding found for \",len(funding),\"authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dataset-955eb4bf66b73016354c', 'dataset-fc71e81f1f2c4130d897', 'dataset-ae01c2bf3451493f3620', 'dataset-cb23c2370049f4960a3a'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can access all results if need to report out differently, eg number of datasets:\n",
    "len(dataset_metrics['dataset-955eb4bf66b73016354c']['combinedDatasets'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
